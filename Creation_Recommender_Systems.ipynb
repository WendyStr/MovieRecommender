{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommender System - Creation Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content of this notebook\n",
    "\n",
    "1. General recommendations\n",
    "2. Recommendations based on content\n",
    "3. Recommendations based on collaborative filtering\n",
    "<br>\n",
    "    3.1 Item-item memory based\n",
    "    <br>\n",
    "    3.2 Model based\n",
    "\n",
    "*For the preparation and exploration of the data, please see the notebook named 'Data_Preparation_and_Exploration'*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import unidecode\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import SVD, SVDpp, KNNWithMeans, NMF, SlopeOne, Dataset, Reader, accuracy\n",
    "from surprise.model_selection import GridSearchCV, cross_validate\n",
    "from surprise.model_selection.split import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unpickle the dataframes prepared in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/df_small.pkl', 'rb') as f_dfsmall:\n",
    "    df_small = pickle.load(f_dfsmall)\n",
    "    \n",
    "with open('pickles/df_expand_genres.pkl', 'rb') as f_dfgenres:\n",
    "    df_expand_genres = pickle.load(f_dfgenres)\n",
    "    \n",
    "with open('pickles/genres.pkl', 'rb') as f_genres:\n",
    "    genres = pickle.load(f_genres)\n",
    "    \n",
    "with open('pickles/ratings.pkl', 'rb') as f_ratings:\n",
    "    ratings = pickle.load(f_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. General recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I will prepare a simple function that will recommend movies based on their weighted vote average, with the option to filter by genre and original language. This is a very general way of recommending movies, without any personalization other than the provided filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_recommendation(genre=None, original_language=None, quantity=10, ):\n",
    "    \n",
    "    '''Function that will recommend movies based on their weighted vote average,\n",
    "    with the option to filter by genre and original language.\n",
    "    \n",
    "    Parameters\n",
    "    ----------------\n",
    "    - genre: str\n",
    "    - original_language: str\n",
    "    - quantity: int, quantity of recommendations to return\n",
    "    \n",
    "    '''\n",
    "    df_small_sorted = df_small.sort_values('weighted_vote_average', ascending=False)\n",
    "    df_expand_genres_sorted = df_expand_genres.sort_values('weighted_vote_average', ascending=False)\n",
    "    \n",
    "    if genre == None:\n",
    "        if original_language == None:\n",
    "            df = df_small_sorted[['title','weighted_vote_average']].head(quantity)\n",
    "        else:\n",
    "            df = df_small_sorted.loc[(df_small_sorted.original_language == original_language)]\n",
    "            df = df[['title','weighted_vote_average']].head(quantity)\n",
    "    \n",
    "    else:\n",
    "        if original_language == None:                                     \n",
    "            df = df_expand_genres_sorted.loc[(df_expand_genres_sorted.genres_list == genre)]\n",
    "            df = df[['title','weighted_vote_average']].drop_duplicates().head(quantity)\n",
    "        else:                                         \n",
    "            df = df_expand_genres_sorted.loc[(df_expand_genres_sorted.original_language == original_language)&\\\n",
    "                                      (df_expand_genres_sorted.genres_list == genre)]\n",
    "            df = df[['title','weighted_vote_average']].drop_duplicates().head(quantity)\n",
    "    \n",
    "    df.index = np.arange(1, len(df) + 1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>weighted_vote_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>8.243606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Empire Strikes Back</td>\n",
       "      <td>8.093833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inception</td>\n",
       "      <td>8.055753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>8.025639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Star Wars</td>\n",
       "      <td>8.010571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Lord of the Rings: The Fellowship of the Ring</td>\n",
       "      <td>7.934962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Lord of the Rings: The Two Towers</td>\n",
       "      <td>7.924803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Guardians of the Galaxy</td>\n",
       "      <td>7.845535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Matrix</td>\n",
       "      <td>7.840144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Scarface 1983</td>\n",
       "      <td>7.822081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  weighted_vote_average\n",
       "1                                     The Dark Knight               8.243606\n",
       "2                             The Empire Strikes Back               8.093833\n",
       "3                                           Inception               8.055753\n",
       "4       The Lord of the Rings: The Return of the King               8.025639\n",
       "5                                           Star Wars               8.010571\n",
       "6   The Lord of the Rings: The Fellowship of the Ring               7.934962\n",
       "7               The Lord of the Rings: The Two Towers               7.924803\n",
       "8                             Guardians of the Galaxy               7.845535\n",
       "9                                          The Matrix               7.840144\n",
       "10                                      Scarface 1983               7.822081"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_recommendation(genre='Action', original_language='en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Recommendations based on content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make a recommendation based on characteristics of the movies, I will generate a large string that contains the genres, main actors, directors and production companies of each movie. After, I will use the cosine similarity to calculate the similarity between movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I will create a copy of the original dataframe containing only the columns that I will use for the content based recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_small[['title','movieId','genres_list','cast_top3','director_list', 'prodcompany_list', 'keywords_list']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will create a small function that will convert lists to strings. In case a list item consists of multiple words, these words are joined together. This is to avoid similarities between movies that shouldn't be there. For example, movies with the actors Tom Hanks and Tom Cruise, will both have the word 'Tom' in common. This does not mean though that these movies are 'similar'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_string(x):\n",
    "    listado = [str.lower(i.replace(\" \", \"\")) for i in x]\n",
    "    return ' '.join(listado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the 'list_to_string' function on the features of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['genres_list','cast_top3','director_list','prodcompany_list','keywords_list']\n",
    "\n",
    "for feature in features:\n",
    "    df2[feature] = df2[feature].apply(list_to_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a new column that combines the different strings with features into one large string and clean this string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['features_combined'] = df2.genres_list.str.cat([df2.cast_top3, df2.director_list, df2.prodcompany_list], sep=' ')\n",
    "df2['features_combined'] = df2['features_combined'].apply(lambda x: unidecode.unidecode(x))\n",
    "df2['features_combined'] = df2['features_combined'].apply(lambda x: re.sub(r'([^\\s\\w]|_)+','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'animation comedy family tomhanks timallen donrickles johnlasseter pixaranimationstudios'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.features_combined[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizing the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer().fit(df2['features_combined'])\n",
    "features_vectorized = vectorizer.transform(df2['features_combined'])\n",
    "features_vectorized = features_vectorized.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9010, 20924)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickles/features_vectorized.pkl', 'wb') as f_vecfeatures:\n",
    "    pickle.dump(features_vectorized, f_vecfeatures) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the cosine similarity to calculate the similarity between the features of the different movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "csim_features = cosine_similarity(features_vectorized)\n",
    "csim_features = pd.DataFrame(csim_features, columns=df2.title, index=df2.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9010, 9010)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csim_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function that will recommend movies that are similar to the input movie based on the following features: genres, main actors, directors and production companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation_content(title, quantity=10):\n",
    "    \n",
    "    '''Function that takes an input movie and recommends movies with similar features as the input movie.\n",
    "    \n",
    "    Parameters\n",
    "    ----------------\n",
    "    - title: str, title of the input movie\n",
    "    - quantity: int, quantity of recommendations to return\n",
    "    \n",
    "    '''\n",
    "            \n",
    "    df_similar_features = pd.DataFrame(csim_features.loc[title].sort_values(ascending=False)).reset_index()\n",
    "    df_similar_features.columns = ['title', 'cosine_sim']\n",
    "    df_similar_features = df_similar_features.merge(df_small[['title', 'weighted_vote_average']], on='title')\n",
    "    df_similar_features = df_similar_features.drop(df_similar_features[df_similar_features.title == title].index)\n",
    "    df_similar_features = df_similar_features.drop(df_similar_features[df_similar_features.weighted_vote_average<7].index)\n",
    "        \n",
    "    return df_similar_features.head(quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 76.4 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>cosine_sim</th>\n",
       "      <th>weighted_vote_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>0.880705</td>\n",
       "      <td>7.552751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Batman Begins</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>7.446915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Prestige</td>\n",
       "      <td>0.613941</td>\n",
       "      <td>7.876536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Inception</td>\n",
       "      <td>0.480384</td>\n",
       "      <td>8.055753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Heat</td>\n",
       "      <td>0.418121</td>\n",
       "      <td>7.481785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>0.400320</td>\n",
       "      <td>8.044694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Training Day</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>7.130469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Scarface 1983</td>\n",
       "      <td>0.369800</td>\n",
       "      <td>7.822081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Dirty Harry</td>\n",
       "      <td>0.369800</td>\n",
       "      <td>7.017779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>M</td>\n",
       "      <td>0.369800</td>\n",
       "      <td>7.277003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title  cosine_sim  weighted_vote_average\n",
       "1   The Dark Knight Rises    0.880705               7.552751\n",
       "2           Batman Begins    0.846154               7.446915\n",
       "3            The Prestige    0.613941               7.876536\n",
       "4               Inception    0.480384               8.055753\n",
       "13                   Heat    0.418121               7.481785\n",
       "19           Interstellar    0.400320               8.044694\n",
       "37           Training Day    0.384615               7.130469\n",
       "49          Scarface 1983    0.369800               7.822081\n",
       "52            Dirty Harry    0.369800               7.017779\n",
       "59                      M    0.369800               7.277003"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "recommendation_content('The Dark Knight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Recommendations based on collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a recommender system based on collaborative filtering models, I will use the Surprise library (a Python scikit for building and analyzing recommendation systems dealing with explicit rating data).\n",
    "\n",
    "Documentation: http://surpriselib.com/\n",
    "\n",
    "Instead of basing the recommendations on the movies characteristics, these recommendations wll be solely based on users ratings. The ratings dataframe contains ratings with a scale from 0 to 5 given by 671 users. For collaborative filtering models, a bigger dataset with more different users would be ideal. However, due to computational limitations, I will have to work with this smaller subset of 671 users.\n",
    "\n",
    "I will try out several types of models and afterwards choose the one that works best for my dataset:\n",
    "\n",
    "1. **Item-item memory based**: \n",
    "    - **KNNwithMeans**. KNN does not make any assumptions about the distribution of the data, it is based only on the similarity of the features. KNNwithMeans takes into account the average of the ratings each user gives to correct for their level of optimism.\n",
    "<br>\n",
    "<br>\n",
    "2. **Model based**:\n",
    "   - **Slope One** algorithm\n",
    "   - **Matrix Factorization**: I will try out both the **SVD** and **NMF** algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation metrics used in this section:\n",
    "\n",
    "- **RMSE**: Root Mean Squared Error. This metric will tell me how well my model predicts the users ratings.\n",
    "- **FCP**: Fraction of Concordant Pairs, the proportion of item pairs that were correctly ranked. This metric will tell me how well my model predicts the order of users preferences.\n",
    "- **Precision@K**: The proportion of items recommended in the top-K that are relevant (rating>=3.5). This will tell me how relevant the recommended items are to the user.\n",
    "- **Recall@K**: The proportion of relevant elements (rating>=3.5) found in the top-K recommendations. This will tell me what percentage of the relevant items are recommended by my model.\n",
    "- **Coverage**: The percentage of items included in all the recommendations over the number of potential items. This metric will tell me how diverse my recommendations are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       1       31     2.5\n",
       "1       1     1029     3.0\n",
       "2       1     1061     3.0\n",
       "3       1     1129     2.0\n",
       "4       1     1172     4.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset into a train and test set. I will use 80% of the data for the train set and 20% for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_original, data_test_original = train_test_split(ratings, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80003, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20001, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models in the Surprise library requiere the input data to have a specific format. Below I will use several functions of the Surprise library to prepare the input data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_train = Reader(rating_scale=(data_train_original[\"rating\"].min(),data_train_original[\"rating\"].max()))\n",
    "data_train = Dataset.load_from_df(data_train_original,reader_train)\n",
    "\n",
    "reader_test = Reader(rating_scale=(data_test_original[\"rating\"].min(),data_test_original[\"rating\"].max()))\n",
    "data_test = Dataset.load_from_df(data_test_original,reader_test)\n",
    "\n",
    "reader_full = Reader(rating_scale=(ratings[\"rating\"].min(),ratings[\"rating\"].max()))\n",
    "data_full = Dataset.load_from_df(ratings,reader_full)\n",
    "\n",
    "trainset = data_train.build_full_trainset()\n",
    "\n",
    "testset = data_test.build_full_trainset()\n",
    "testset = testset.build_testset()\n",
    "\n",
    "anti_testset = data_test.build_full_trainset()\n",
    "anti_testset = anti_testset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will  create a function to calculate the following evaluation metrics: Precision@K, Recall@K and Coverage. The evaluation metrics RMSE and FCP are included in the Surprise library, and have already been imported at the beginning of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code source: https://surprise.readthedocs.io/en/stable/FAQ.html\n",
    "\n",
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code source: https://surprise.readthedocs.io/en/stable/FAQ.html\n",
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage(predictions, n=10, dataset_original=data_test_original):\n",
    "    '''Returns the percentage of movies included in the different recommendation lists\n",
    "    (top-n) over the total number of movies.'''\n",
    "\n",
    "    top_n = get_top_n(predictions, n=n)\n",
    "\n",
    "    recommendations = []\n",
    "\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        for (iid, _) in user_ratings:\n",
    "            recommendations.append(iid)\n",
    "        \n",
    "    unique_movies_recommended = len(set(recommendations))\n",
    "    unique_movies_testset = dataset_original.movieId.nunique()\n",
    "\n",
    "    coverage = unique_movies_recommended/unique_movies_testset\n",
    "    \n",
    "    return coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Item-Item Memory Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I will try out the **KNNwithMeans** algorithm.\n",
    "<br>\n",
    "<br>\n",
    "The gridsearch of Surprise allows to optimize for RMSE, MSE, MAE, and FCP. I will use the best FCP hyperparameters, because the most important thing for me is to rank the movies in the correct order. I have commented out the gridsearch section, because it is computationally heavy, but I am using the best hyperparameters obtained by this gridsearch earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_grid = {'min_k': [20, 50],\n",
    "#              'sim_options': {'name': ['msd', 'cosine','pearson'],\n",
    "#                              'min_support': [1, 5],\n",
    "#                              'user_based': [False]}\n",
    "#              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_knn = GridSearchCV(KNNWithMeans, param_grid, measures=['rmse','fcp'], refit=True, cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#grid_knn.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_knn.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_knn.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will train the KNNWithMeans algorithm with the trainset and the hyperparameters obtained in the gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_options = {\"name\": \"msd\", \"min_support\":1, \"user_based\": False}\n",
    "k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Wall time: 10.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x289ec5b0dd8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_KNN = KNNWithMeans(sim_options=sim_options, min_k=k)\n",
    "model_KNN.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will predict the recommendations based on the testset, and calculate the RMSE, FCP, Precision@K and Recall@K.\n",
    "<br>\n",
    "<br>\n",
    "*Note: Due to computational limitations of my laptop, I cannot calculate the coverage metric for KNNWithMeans. KNNWithMeans is a memory based algorithm. For the coverage metric, I would need to calculate the recommendations for all users taking into account all the movies in the testset. My computer does not have enough memory to do so. The other metrics only take into account the movies evaluated by the user, and not all movies in the dataset, and are therefore lighter to calculate.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0019\n",
      "FCP:  0.6488\n"
     ]
    }
   ],
   "source": [
    "pred_KNN_test = model_KNN.test(testset)\n",
    "\n",
    "RMSE = accuracy.rmse(pred_KNN_test)\n",
    "FCP = accuracy.fcp(pred_KNN_test)\n",
    "\n",
    "precisions, recalls = precision_recall_at_k(pred_KNN_test)\n",
    "\n",
    "Precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "Recall = sum(rec for rec in recalls.values()) / len(recalls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will add the results of the evaluation metrics to a dateframe that I will use to compare the different algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=[['model','RMSE', 'FCP', 'Precision@K', 'Recall@K']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[0, 'model'] = 'KNNWithMeans'\n",
    "results.loc[0, 'RMSE'] = RMSE\n",
    "results.loc[0, 'FCP'] = FCP\n",
    "results.loc[0, 'Precision@K'] = Precision\n",
    "results.loc[0, 'Recall@K'] = Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>FCP</th>\n",
       "      <th>Precision@K</th>\n",
       "      <th>Recall@K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNNWithMeans</td>\n",
       "      <td>1.00185</td>\n",
       "      <td>0.648809</td>\n",
       "      <td>0.777222</td>\n",
       "      <td>0.554911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model     RMSE       FCP Precision@K  Recall@K\n",
       "0  KNNWithMeans  1.00185  0.648809    0.777222  0.554911"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Model-based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slope One"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, I will try out the Slope One algorithm. This algorithm does not have any hyperparameters to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_SlopeOne = SlopeOne()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.57 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.slope_one.SlopeOne at 0x289ecbbcac8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_SlopeOne.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will predict the recommendations based on the testset, and calculate the RMSE, FCP, Precision@K, Recall@K and Coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9305\n",
      "FCP:  0.6421\n"
     ]
    }
   ],
   "source": [
    "pred_SlopeOne_test = model_SlopeOne.test(testset)\n",
    "\n",
    "RMSE = accuracy.rmse(pred_SlopeOne_test)\n",
    "FCP = accuracy.fcp(pred_SlopeOne_test)\n",
    "\n",
    "precisions, recalls = precision_recall_at_k(pred_SlopeOne_test)\n",
    "\n",
    "Precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "Recall = sum(rec for rec in recalls.values()) / len(recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_SlopeOne_antitest = model_SlopeOne.test(anti_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Coverage = coverage(pred_SlopeOne_antitest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[1, 'model'] = 'Slope One'\n",
    "results.loc[1, 'RMSE'] = RMSE\n",
    "results.loc[1, 'FCP'] = FCP\n",
    "results.loc[1, 'Precision@K'] = Precision\n",
    "results.loc[1, 'Recall@K'] = Recall\n",
    "results.loc[1, 'Coverage'] = Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>FCP</th>\n",
       "      <th>Precision@K</th>\n",
       "      <th>Recall@K</th>\n",
       "      <th>Coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNNWithMeans</td>\n",
       "      <td>1.00185</td>\n",
       "      <td>0.648809</td>\n",
       "      <td>0.777222</td>\n",
       "      <td>0.554911</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Slope One</td>\n",
       "      <td>0.930466</td>\n",
       "      <td>0.642111</td>\n",
       "      <td>0.782997</td>\n",
       "      <td>0.527836</td>\n",
       "      <td>0.081767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model      RMSE       FCP Precision@K  Recall@K  Coverage\n",
       "0  KNNWithMeans   1.00185  0.648809    0.777222  0.554911       NaN\n",
       "1     Slope One  0.930466  0.642111    0.782997  0.527836  0.081767"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix Factorization - SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, I will try out the **SVD** algorithm.\n",
    "<br>\n",
    "<br>\n",
    "The gridsearch of Surprise allows to optimize for RMSE, MSE, MAE, and FCP. I will use the best FCP hyperparameters, because the most important thing for me is to rank the movies in the correct order. I have commented out the gridsearch section, because it is computationally heavy, but I am using the best hyperparameters obtained by this gridsearch earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_grid = {'n_epochs': [20, 30, 50],\n",
    "#              'biased': [True, False],\n",
    "#              'lr_all': [0.005, 0.01, 0.1],\n",
    "#              'reg_all': [0.05, 0.1, 0.3]\n",
    "#              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_SVD = GridSearchCV(SVD, param_grid, cv=kf, n_jobs=-1, refit=True, measures = [\"rmse\",\"fcp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#grid_SVD.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_SVD.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_SVD.best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will train the SVD algorithm with the trainset and the hyperparameters obtained in the gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_SVD = SVD(n_epochs=30, biased=True, lr_all=0.01, reg_all=0.1, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x28a5c23e748>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_SVD.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will predict the recommendations based on the testset, and calculate the RMSE, FCP, Precision@K and Recall@K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8791\n",
      "FCP:  0.6641\n"
     ]
    }
   ],
   "source": [
    "pred_SVD_test = model_SVD.test(testset)\n",
    "\n",
    "RMSE = accuracy.rmse(pred_SVD_test)\n",
    "FCP = accuracy.fcp(pred_SVD_test)\n",
    "\n",
    "precisions, recalls = precision_recall_at_k(pred_SVD_test)\n",
    "\n",
    "Precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "Recall = sum(rec for rec in recalls.values()) / len(recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_SVD_antitest = model_SVD.test(anti_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Coverage = coverage(pred_SVD_antitest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[2, 'model'] = 'SVD'\n",
    "results.loc[2, 'RMSE'] = RMSE\n",
    "results.loc[2, 'FCP'] = FCP\n",
    "results.loc[2, 'Precision@K'] = Precision\n",
    "results.loc[2, 'Recall@K'] = Recall\n",
    "results.loc[2, 'Coverage'] = Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>FCP</th>\n",
       "      <th>Precision@K</th>\n",
       "      <th>Recall@K</th>\n",
       "      <th>Coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNNWithMeans</td>\n",
       "      <td>1.00185</td>\n",
       "      <td>0.648809</td>\n",
       "      <td>0.777222</td>\n",
       "      <td>0.554911</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Slope One</td>\n",
       "      <td>0.930466</td>\n",
       "      <td>0.642111</td>\n",
       "      <td>0.782997</td>\n",
       "      <td>0.527836</td>\n",
       "      <td>0.081767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVD</td>\n",
       "      <td>0.879087</td>\n",
       "      <td>0.664126</td>\n",
       "      <td>0.808234</td>\n",
       "      <td>0.539637</td>\n",
       "      <td>0.078670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model      RMSE       FCP Precision@K  Recall@K  Coverage\n",
       "0  KNNWithMeans   1.00185  0.648809    0.777222  0.554911       NaN\n",
       "1     Slope One  0.930466  0.642111    0.782997  0.527836  0.081767\n",
       "2           SVD  0.879087  0.664126    0.808234  0.539637  0.078670"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix Factorization - NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I will try out the **NMF** algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_grid = {'n_factors': [10, 15, 20],\n",
    "#              'n_epochs': [20, 50, 100],\n",
    "#              'biased': [True, False],\n",
    "#              'reg_pu': [0.01, 0.06, 0.1],\n",
    "#              'reg_qi': [0.01, 0.06, 0.1]\n",
    "#              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_NMF = GridSearchCV(NMF, param_grid, cv=kf, n_jobs=-1, refit=True, measures = [\"rmse\",\"fcp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#grid_NMF.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_NMF.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_NMF.best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will train the NMF algorithm with the trainset and the hyperparameters obtained in the gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_NMF = NMF(n_factors=10, n_epochs=100, biased=False, reg_pu=0.1, reg_qi=0.1, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.NMF at 0x28aa71d0e48>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_NMF.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will predict the recommendations based on the testset, and calculate the RMSE, FCP, Precision@K, Recall@K and Coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9372\n",
      "FCP:  0.6504\n"
     ]
    }
   ],
   "source": [
    "pred_NMF_test = model_NMF.test(testset)\n",
    "\n",
    "RMSE = accuracy.rmse(pred_NMF_test)\n",
    "FCP = accuracy.fcp(pred_NMF_test)\n",
    "\n",
    "precisions, recalls = precision_recall_at_k(pred_NMF_test)\n",
    "\n",
    "Precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "Recall = sum(rec for rec in recalls.values()) / len(recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_NMF_antitest = model_NMF.test(anti_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Coverage = coverage(pred_NMF_antitest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[3, 'model'] = 'NMF'\n",
    "results.loc[3, 'RMSE'] = RMSE\n",
    "results.loc[3, 'FCP'] = FCP\n",
    "results.loc[3, 'Precision@K'] = Precision\n",
    "results.loc[3, 'Recall@K'] = Recall\n",
    "results.loc[3, 'Coverage'] = Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>FCP</th>\n",
       "      <th>Precision@K</th>\n",
       "      <th>Recall@K</th>\n",
       "      <th>Coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNNWithMeans</td>\n",
       "      <td>1.00185</td>\n",
       "      <td>0.648809</td>\n",
       "      <td>0.777222</td>\n",
       "      <td>0.554911</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Slope One</td>\n",
       "      <td>0.930466</td>\n",
       "      <td>0.642111</td>\n",
       "      <td>0.782997</td>\n",
       "      <td>0.527836</td>\n",
       "      <td>0.081767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVD</td>\n",
       "      <td>0.879087</td>\n",
       "      <td>0.664126</td>\n",
       "      <td>0.808234</td>\n",
       "      <td>0.539637</td>\n",
       "      <td>0.078670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NMF</td>\n",
       "      <td>0.937238</td>\n",
       "      <td>0.650421</td>\n",
       "      <td>0.808056</td>\n",
       "      <td>0.492116</td>\n",
       "      <td>0.114598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model      RMSE       FCP Precision@K  Recall@K  Coverage\n",
       "0  KNNWithMeans   1.00185  0.648809    0.777222  0.554911       NaN\n",
       "1     Slope One  0.930466  0.642111    0.782997  0.527836  0.081767\n",
       "2           SVD  0.879087  0.664126    0.808234  0.539637  0.078670\n",
       "3           NMF  0.937238  0.650421    0.808056  0.492116  0.114598"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVD algorithm has the best scores for RMSE, FCP and Precision@K. However, it has a low Coverage, meaning that there is little variation between its recommendations. I cannot optimize for Coverage because it is computationally too heavy, but I will try to optimize the SVD algorithm for Precision@K instead of FCP, to see if it changes the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will create two functions that will allow me to optimize the hyperparameters of SVD for Precision@K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_hyperparameters_SVD():\n",
    "\n",
    "    while True:\n",
    "        yield {\n",
    "            \"n_epochs\": np.random.randint(10, 50),\n",
    "            \"biased\": np.random.choice([False, True]),\n",
    "            \"lr_all\": np.random.choice([0.005, 0.01, 0.1]),\n",
    "            \"reg_all\": np.random.choice([0.05, 0.1, 0.3]),\n",
    "        }\n",
    "\n",
    "def random_search_precision_SVD(data_train, data_test, num_samples=10):\n",
    "\n",
    "    for hyperparams in itertools.islice(sample_hyperparameters_SVD(), num_samples):\n",
    "        \n",
    "        model = SVD(**hyperparams)\n",
    "        trainset = data_train.build_full_trainset()\n",
    "        model.fit(trainset)\n",
    "        \n",
    "        testset = data_test.build_full_trainset()\n",
    "        testset = testset.build_testset()\n",
    "        pred = model.test(testset)\n",
    "        \n",
    "        precisions, recalls = precision_recall_at_k(pred)\n",
    "        score = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "\n",
    "        yield (score, hyperparams, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(score, hyperparams, model) = max(random_search_precision_SVD(data_train, data_test), key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Best score {} at {}\".format(score, hyperparams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will train the SVD model on the trainset with the best hyperparameters obtained in the random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x289a4979f28>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_SVD = SVD(n_epochs=37, biased=True, lr_all=0.01, reg_all=0.1, random_state=4)\n",
    "model_SVD.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will predict the recommendations based on the testset, and calculate the RMSE, FCP, Precision@K, Recall@K and Coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8773\n",
      "FCP:  0.6680\n"
     ]
    }
   ],
   "source": [
    "pred_SVD = model_SVD.test(testset)\n",
    "\n",
    "RMSE = accuracy.rmse(pred_SVD)\n",
    "FCP = accuracy.fcp(pred_SVD)\n",
    "\n",
    "precisions, recalls = precision_recall_at_k(pred_SVD)\n",
    "\n",
    "Precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "Recall = sum(rec for rec in recalls.values()) / len(recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_antitest_SVD = model_SVD.test(anti_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "Coverage = coverage(pred_antitest_SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8772617423261785\n",
      "FCP 0.6680481350683322\n",
      "Precision@K: 0.8095457237621412\n",
      "Recall@K 0.5426622859350428\n",
      "Coverage 0.09436299814164774\n"
     ]
    }
   ],
   "source": [
    "print('RMSE:', RMSE)\n",
    "print('FCP', FCP)\n",
    "print('Precision@K:', Precision)\n",
    "print('Recall@K', Recall)\n",
    "print('Coverage', Coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[2, 'model'] = 'SVD'\n",
    "results.loc[2, 'RMSE'] = RMSE\n",
    "results.loc[2, 'FCP'] = FCP\n",
    "results.loc[2, 'Precision@K'] = Precision\n",
    "results.loc[2, 'Recall@K'] = Recall\n",
    "results.loc[2, 'Coverage'] = Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>FCP</th>\n",
       "      <th>Precision@K</th>\n",
       "      <th>Recall@K</th>\n",
       "      <th>Coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNNWithMeans</td>\n",
       "      <td>1.00185</td>\n",
       "      <td>0.648809</td>\n",
       "      <td>0.777222</td>\n",
       "      <td>0.554911</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Slope One</td>\n",
       "      <td>0.930466</td>\n",
       "      <td>0.642111</td>\n",
       "      <td>0.782997</td>\n",
       "      <td>0.527836</td>\n",
       "      <td>0.081767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVD</td>\n",
       "      <td>0.877262</td>\n",
       "      <td>0.668048</td>\n",
       "      <td>0.809546</td>\n",
       "      <td>0.542662</td>\n",
       "      <td>0.094363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NMF</td>\n",
       "      <td>0.937238</td>\n",
       "      <td>0.650421</td>\n",
       "      <td>0.808056</td>\n",
       "      <td>0.492116</td>\n",
       "      <td>0.114598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model      RMSE       FCP Precision@K  Recall@K  Coverage\n",
       "0  KNNWithMeans   1.00185  0.648809    0.777222  0.554911       NaN\n",
       "1     Slope One  0.930466  0.642111    0.782997  0.527836  0.081767\n",
       "2           SVD  0.877262  0.668048    0.809546  0.542662  0.094363\n",
       "3           NMF  0.937238  0.650421    0.808056  0.492116  0.114598"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics have improved a bit. However, the coverage of SVD remains low, and lower than the NMF coverage.\n",
    "<br>\n",
    "<br>\n",
    "To have more variation in the recommendations I will use the NMF model for the final movie recommender, which has the highest coverage and the other metrics are also acceptable to me. I will also try to optimize the NFM model for Precision@K to see if it improves its results compared to the FCP-optimized model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will create two functions that will allow me to optimize the hyperparameters of NMF for Precision@K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_hyperparameters_NMF():\n",
    "\n",
    "    while True:\n",
    "        yield {\n",
    "            \"n_factors\": np.random.randint(10,20),\n",
    "            \"n_epochs\": np.random.randint(20, 100),\n",
    "            \"biased\": np.random.choice([False, True]),\n",
    "            \"reg_pu\": np.random.choice([0.01, 0.05, 0.1]),\n",
    "            \"reg_qi\": np.random.choice([0.01, 0.04, 0.1]),\n",
    "        }\n",
    "\n",
    "def random_search_precision_NMF(data_train, data_test, num_samples=10):\n",
    "\n",
    "    for hyperparams in itertools.islice(sample_hyperparameters_NMF(), num_samples):\n",
    "        \n",
    "        model = NMF(**hyperparams)\n",
    "        trainset = data_train.build_full_trainset()\n",
    "        model.fit(trainset)\n",
    "        \n",
    "        testset = data_test.build_full_trainset()\n",
    "        testset = testset.build_testset()\n",
    "        pred = model.test(testset)\n",
    "        \n",
    "        precisions, recalls = precision_recall_at_k(pred)\n",
    "        score = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "\n",
    "        yield (score, hyperparams, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(score, hyperparams, model) = max(random_search_precision_NMF(data_train, data_test), key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Best score {} at {}\".format(score, hyperparams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will train the NMF model on the train set with the best hyperparameters obtained in the random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.NMF at 0x289eb3c90b8>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_NMF = NMF(n_factors=11, n_epochs=40, biased=True, reg_pu=0.01, reg_qi=0.1, random_state=4)\n",
    "model_NMF.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will predict the recommendations based on the testset, and calculate the RMSE, FCP, Precision@K, Recall@K and Coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9120\n",
      "FCP:  0.6507\n"
     ]
    }
   ],
   "source": [
    "pred_NMF = model_NMF.test(testset)\n",
    "\n",
    "RMSE = accuracy.rmse(pred_NMF)\n",
    "FCP = accuracy.fcp(pred_NMF)\n",
    "\n",
    "precisions, recalls = precision_recall_at_k(pred_NMF)\n",
    "\n",
    "Precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "Recall = sum(rec for rec in recalls.values()) / len(recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_antitest_NMF = model_NMF.test(anti_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "Coverage = coverage(pred_antitest_NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9119941305523163\n",
      "FCP 0.6507272280086235\n",
      "Precision@K: 0.8005152807391607\n",
      "Recall@K 0.5244361095511496\n",
      "Coverage 0.08920090852777204\n"
     ]
    }
   ],
   "source": [
    "print('RMSE:', RMSE)\n",
    "print('FCP', FCP)\n",
    "print('Precision@K:', Precision)\n",
    "print('Recall@K', Recall)\n",
    "print('Coverage', Coverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although optimizing for Precision@K improves some metrics of the NMF model, it lowers the coverage. For the final recommender system I will use the hyperparameters obtained when optimizing for FCP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final model with collaborative filtering - NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I will create a function for the recommender system based on collaborative filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation_nmf(my_ratings, n=10):\n",
    "    \n",
    "    '''This functions takes a list of user ratings as an input and \n",
    "    returns a recommendation comparing these ratings with other users \n",
    "    ratings in the dataset. It uses an NMF algorithm.'''\n",
    "    \n",
    "    \n",
    "    ratings2 = ratings.append(my_ratings)\n",
    "    reader = Reader(rating_scale=(ratings2[\"rating\"].min(),ratings2[\"rating\"].max()))\n",
    "    data = Dataset.load_from_df(ratings2,reader)\n",
    "    \n",
    "    model_NMF = NMF(n_factors=10, n_epochs=100, biased=False, reg_pu=0.1, reg_qi=0.1, random_state=4)\n",
    "    trainset = data.build_full_trainset()\n",
    "    model_NMF.fit(trainset)\n",
    "    \n",
    "    testset = trainset.build_anti_testset()\n",
    "    predictions = model_NMF.test(testset[-9066:-1])\n",
    "    \n",
    "    userid = max(ratings2.userId)\n",
    "    top_n = []\n",
    "    \n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        if uid==userid:\n",
    "            top_n.append((iid, est))\n",
    "        \n",
    "    top_n.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_n = pd.DataFrame([x[0] for x in top_n], columns=['movieId'])\n",
    "    top_n = top_n.merge(df_small[['title', 'movieId', 'weighted_vote_average']], on='movieId')\n",
    "    top_n = top_n.drop(top_n[top_n.weighted_vote_average<7].index)\n",
    "    \n",
    "    return top_n.head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying out the model with random input ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ratings = []\n",
    "\n",
    "for x in range(20):\n",
    "    my_ratings.append({'userId': (max(ratings.userId)+1),\\\n",
    "                        'movieId':ratings.movieId.sample().tolist()[0],\\\n",
    "                        'rating':np.random.randint(1,5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>weighted_vote_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>89774</td>\n",
       "      <td>Warrior</td>\n",
       "      <td>7.404591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>73881</td>\n",
       "      <td>3 Idiots</td>\n",
       "      <td>7.365964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>26903</td>\n",
       "      <td>Whisper of the Heart</td>\n",
       "      <td>7.014008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2810</td>\n",
       "      <td>Perfect Blue</td>\n",
       "      <td>7.001023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1232</td>\n",
       "      <td>Stalker</td>\n",
       "      <td>7.069812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>26776</td>\n",
       "      <td>Porco Rosso</td>\n",
       "      <td>7.111218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1298</td>\n",
       "      <td>Pink Floyd: The Wall</td>\n",
       "      <td>7.027146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>115122</td>\n",
       "      <td>What We Do in the Shadows</td>\n",
       "      <td>7.067431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>103235</td>\n",
       "      <td>The Best Offer</td>\n",
       "      <td>7.247510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>3386</td>\n",
       "      <td>JFK</td>\n",
       "      <td>7.025248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     movieId                      title  weighted_vote_average\n",
       "38     89774                    Warrior               7.404591\n",
       "49     73881                   3 Idiots               7.365964\n",
       "58     26903       Whisper of the Heart               7.014008\n",
       "67      2810               Perfect Blue               7.001023\n",
       "70      1232                    Stalker               7.069812\n",
       "83     26776                Porco Rosso               7.111218\n",
       "97      1298       Pink Floyd: The Wall               7.027146\n",
       "123   115122  What We Do in the Shadows               7.067431\n",
       "192   103235             The Best Offer               7.247510\n",
       "215     3386                        JFK               7.025248"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "recommendation_nmf(my_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ratings = []\n",
    "\n",
    "for x in range(20):\n",
    "    my_ratings.append({'userId': (max(ratings.userId)+1),\\\n",
    "                        'movieId':ratings.movieId.sample().tolist()[0],\\\n",
    "                        'rating':np.random.randint(1,5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>weighted_vote_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2810</td>\n",
       "      <td>Perfect Blue</td>\n",
       "      <td>7.001023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>26776</td>\n",
       "      <td>Porco Rosso</td>\n",
       "      <td>7.111218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>920</td>\n",
       "      <td>Gone with the Wind</td>\n",
       "      <td>7.339137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>73881</td>\n",
       "      <td>3 Idiots</td>\n",
       "      <td>7.365964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1298</td>\n",
       "      <td>Pink Floyd: The Wall</td>\n",
       "      <td>7.027146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1230</td>\n",
       "      <td>Annie Hall</td>\n",
       "      <td>7.425597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>923</td>\n",
       "      <td>Citizen Kane</td>\n",
       "      <td>7.626392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2739</td>\n",
       "      <td>The Color Purple</td>\n",
       "      <td>7.010159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1204</td>\n",
       "      <td>Lawrence of Arabia</td>\n",
       "      <td>7.372975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>27773</td>\n",
       "      <td>Oldboy 2003</td>\n",
       "      <td>7.745669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     movieId                 title  weighted_vote_average\n",
       "5       2810          Perfect Blue               7.001023\n",
       "45     26776           Porco Rosso               7.111218\n",
       "54       920    Gone with the Wind               7.339137\n",
       "77     73881              3 Idiots               7.365964\n",
       "96      1298  Pink Floyd: The Wall               7.027146\n",
       "113     1230            Annie Hall               7.425597\n",
       "133      923          Citizen Kane               7.626392\n",
       "170     2739      The Color Purple               7.010159\n",
       "180     1204    Lawrence of Arabia               7.372975\n",
       "188    27773           Oldboy 2003               7.745669"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "recommendation_nmf(my_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ratings = []\n",
    "\n",
    "for x in range(20):\n",
    "    my_ratings.append({'userId': (max(ratings.userId)+1),\\\n",
    "                        'movieId':ratings.movieId.sample().tolist()[0],\\\n",
    "                        'rating':np.random.randint(1,5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>weighted_vote_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>71838</td>\n",
       "      <td>Law Abiding Citizen</td>\n",
       "      <td>7.037113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>98491</td>\n",
       "      <td>Paperman</td>\n",
       "      <td>7.453488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>96588</td>\n",
       "      <td>Pitch Perfect</td>\n",
       "      <td>7.171301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>71899</td>\n",
       "      <td>Mary and Max</td>\n",
       "      <td>7.251601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>26903</td>\n",
       "      <td>Whisper of the Heart</td>\n",
       "      <td>7.014008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>55442</td>\n",
       "      <td>Persepolis</td>\n",
       "      <td>7.106687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>95311</td>\n",
       "      <td>Presto</td>\n",
       "      <td>7.185039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>31658</td>\n",
       "      <td>Howl's Moving Castle</td>\n",
       "      <td>7.920374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1172</td>\n",
       "      <td>Cinema Paradiso</td>\n",
       "      <td>7.637723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>3000</td>\n",
       "      <td>Princess Mononoke</td>\n",
       "      <td>7.919445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     movieId                 title  weighted_vote_average\n",
       "15     71838   Law Abiding Citizen               7.037113\n",
       "36     98491              Paperman               7.453488\n",
       "51     96588         Pitch Perfect               7.171301\n",
       "94     71899          Mary and Max               7.251601\n",
       "102    26903  Whisper of the Heart               7.014008\n",
       "128    55442            Persepolis               7.106687\n",
       "135    95311                Presto               7.185039\n",
       "150    31658  Howl's Moving Castle               7.920374\n",
       "173     1172       Cinema Paradiso               7.637723\n",
       "194     3000     Princess Mononoke               7.919445"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "recommendation_nmf(my_ratings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
